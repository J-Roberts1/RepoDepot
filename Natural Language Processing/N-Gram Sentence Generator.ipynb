{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk import word_tokenize\n",
    "import numpy as np"
   ],
   "metadata": {
    "id": "2J9Szm82Cw72",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import Data from txt "
   ],
   "metadata": {
    "id": "ge0lzj6z_-Ox",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "file = open('/content/Article_data/Corpus.txt', 'r') # read a text file\n",
    "filedata = file.readlines()   # filedata is type: list\n",
    "text = ''.join(filedata)      # text is the str of all joined items of list: filedata"
   ],
   "metadata": {
    "id": "G8MqVXIeC1y5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clean Text:\n",
    "- Remove Special characters \n",
    "- Remove newlines \n",
    "- Remove punctuation "
   ],
   "metadata": {
    "id": "n4ec70Nc_9R7",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "specialChars = \"!#$%^&*()[]\\\\/:,;.\"\n",
    "for specialChar in specialChars:\n",
    "    text = text.replace(specialChar, '')"
   ],
   "metadata": {
    "id": "sW0Eb_iUFRMm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "text = text.replace(\"\\n\",' ')\n",
    "text = re.sub(' +', ' ', text)\n",
    "text = text.lower()"
   ],
   "metadata": {
    "id": "JYhoxEDc-AEw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate n-Grams using nltk & .split functions"
   ],
   "metadata": {
    "id": "kV-UnaZPA4GC",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "## Generate n-Grams using nltk & .split functions\n",
    "bigrm = list(nltk.bigrams(text.split()))\n",
    "bi_str_lst = [' '.join(i) for i in bigrm]\n",
    "\n",
    "trigrm = list(nltk.trigrams(text.split()))\n",
    "tri_str_lst = [' '.join(i) for i in trigrm]\n",
    "\n",
    "n = 4\n",
    "fourgrams = ngrams(text.split(), n)\n",
    "quad_str_lst = [' '.join(i) for i in fourgrams]"
   ],
   "metadata": {
    "id": "MuR-yTamW6X-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "words = text.split(\" \")    #List that splits raw str values from 'text' into list values. seperated at the periodfiledata = file.readlines()   # filedata is type: list"
   ],
   "metadata": {
    "id": "C8zoXdIvEAej",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define N-Gram Predictor models and model selection methods \n",
    "Citation: \n",
    "- https://www.geeksforgeeks.org/n-gram-language-modelling-with-nltk/\n",
    "- https://notebook.community/luketurner/ipython-notebooks/notebooks/n-gram%20tutorial\n",
    "- https://github.com/ambatiashok60/Medium/blob/master/Language%20Modeling/N-gram%20Language%20Model%20for%20text%20generation.ipynb"
   ],
   "metadata": {
    "id": "aARVURqyBanN",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class NGrams:\n",
    "    # Defines parameters of class\n",
    "    def __init__(self, words, sentence):\n",
    "        self.words = words\n",
    "        self.sentence = sentence\n",
    "        self.tokens = sentence.split()\n",
    "        \n",
    "    def get_tokens(self):\n",
    "        return self.tokens\n",
    "    \n",
    "    def add_tokens(self,value):\n",
    "        temp = self.tokens\n",
    "        temp.append(value)\n",
    "        self.tokens = temp\n",
    "        return self.tokens\n",
    "\n",
    "    def unigram_model(self):\n",
    "        self.next_words = np.random.choice(words, size=3)\n",
    "        return self.next_words    \n",
    "        \n",
    "    def bigram_model(self):\n",
    "        next_words = []\n",
    "        for i in range(len(words)-1):\n",
    "            if words[i] == self.tokens[-1]:\n",
    "                next_words.append(words[i+1])\n",
    "        self.next_words = next_words\n",
    "        return self.next_words\n",
    "\n",
    "    def trigram_model(self):\n",
    "        next_words = []\n",
    "        for i in range(len(words)-2):\n",
    "            if words[i] == self.tokens[-2]:\n",
    "                if words[i+1] == self.tokens[-1]:\n",
    "                    next_words.append(words[i+2])\n",
    "        self.next_words = next_words\n",
    "        return self.next_words\n",
    "\n",
    "    def fourgram_model(self):\n",
    "        next_words = []\n",
    "        for i in range(len(words)-3):\n",
    "            if words[i] == self.tokens[-3]:\n",
    "                if words[i+1] == self.tokens[-2]:\n",
    "                    if words[i+2] == self.tokens[-1]:\n",
    "                        next_words.append(words[i+3])\n",
    "        self.next_words = next_words\n",
    "        return self.next_words\n",
    "\n",
    "    def get_top_3_next_words(self,next_words):\n",
    "        next_words_dict = dict()\n",
    "        for word in next_words:\n",
    "            if not word in next_words_dict.keys():\n",
    "                next_words_dict[word] = 1\n",
    "            else:\n",
    "                next_words_dict[word] += 1\n",
    "\n",
    "        for i,j in next_words_dict.items():\n",
    "            next_words_dict[i] = np.round(j/len(next_words),2)\n",
    "\n",
    "        return sorted(next_words_dict.items(), key = lambda k:(k[1], k[0]), reverse=True)[:3]\n",
    "\n",
    "\n",
    "    def model_selection(self):\n",
    "        top_words = self.unigram_model()\n",
    "        return top_words\n",
    "\n",
    "    def model_selection_1(self):\n",
    "        next_words = self.bigram_model()\n",
    "        top_words = self.get_top_3_next_words(next_words)\n",
    "        return top_words\n",
    "\n",
    "    def model_selection_2(self):\n",
    "        next_words = self.trigram_model()\n",
    "        top_words = self.get_top_3_next_words(next_words)\n",
    "        return top_words\n",
    "\n",
    "    def model_selection_3(self):\n",
    "        next_words = self.fourgram_model()\n",
    "        top_words = self.get_top_3_next_words(next_words)\n",
    "        return top_words"
   ],
   "metadata": {
    "id": "BVsVmuv3HIBu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Unigram Predictor "
   ],
   "metadata": {
    "id": "EBYrk4WNzuzM",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "gen_sents = []"
   ],
   "metadata": {
    "id": "M4HTi9U250ZU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "from numpy.random import randint\n",
    "for i in range (0,5):\n",
    "  model = NGrams(words=words, sentence=words[randint(0,9841)])\n",
    "  \n",
    "  for i in range(0, 9):\n",
    "    values = model.model_selection()\n",
    "    value = values[randint(0,2)]\n",
    "    model.add_tokens(value)\n",
    "\n",
    "  gen_sents.append(model.get_tokens())"
   ],
   "metadata": {
    "id": "x2Vz7tuc4_Hb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = [' '.join(i) for i in gen_sents]"
   ],
   "metadata": {
    "id": "X-WNe_5v6wBL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in x:\n",
    "  sent = i\n",
    "  print(sent.capitalize() + '.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e06a0507-4430-4344-a7e0-9a74fb160a77",
    "id": "oqG2YiS16wBL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "With dataset on and finance important cryptographic smart as blockchain.\n",
      "Has responses node verified issues monitoring live from included the.\n",
      "Solidity not application transactions date’ force for is and we.\n",
      "Usually finance modifications issues r multiple a security because throughput.\n",
      "Main to and also to data 2 · proposed our.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bigram Predictor\n",
    "use unigram for first word and bigram for 2nd - 10th words\n"
   ],
   "metadata": {
    "id": "mtUgorwz0Fjd",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "gen_sents = []"
   ],
   "metadata": {
    "id": "nZwlopdKnFEg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in range (0,5):\n",
    "  model = NGrams(words=words, sentence=bi_str_lst[randint(0,9852)])\n",
    "  \n",
    "  for j in range(0,8):\n",
    "    values = model.model_selection_1()\n",
    "    vaules_dict = dict(values)\n",
    "    max_value = max(vaules_dict, key=vaules_dict.get)\n",
    "    value = max_value\n",
    "    model.add_tokens(value)\n",
    "\n",
    "  gen_sents.append(model.get_tokens())"
   ],
   "metadata": {
    "id": "PnBQP-e5nFEg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = [' '.join(i) for i in gen_sents]"
   ],
   "metadata": {
    "id": "3Yrfk0-onFEg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in x:\n",
    "  sent = i\n",
    "  print(sent.capitalize() + '.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6e8190c0-bb5e-4770-88d8-6931ad5e5007",
    "id": "s0G_ZqhVnFEg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 65,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In nfts the blockchain technology and the blockchain technology and.\n",
      "Off even more than traditional financial supervision system is a.\n",
      "Blockchainrelated industries must be verified without the blockchain technology and.\n",
      "Al adopts a blockchain technology and the blockchain technology and.\n",
      "The legal effect use a blockchain technology and the blockchain.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Trigram Predictor**"
   ],
   "metadata": {
    "id": "jB3mAKsU1qtr",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "gen_sents = []"
   ],
   "metadata": {
    "id": "fn6MIvzNl-mv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 67,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in range (0,5):\n",
    "  model = NGrams(words=words, sentence=tri_str_lst[randint(0,9851)])\n",
    "  \n",
    "  for j in range(0,7):\n",
    "    values = model.model_selection_2()\n",
    "    vaules_dict = dict(values)\n",
    "    max_value = max(vaules_dict, key=vaules_dict.get)\n",
    "    value = max_value\n",
    "    model.add_tokens(value)\n",
    "\n",
    "  gen_sents.append(model.get_tokens())"
   ],
   "metadata": {
    "id": "dPqTTY0YmDiS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 68,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = [' '.join(i) for i in gen_sents]"
   ],
   "metadata": {
    "id": "QS2FVUHomLgn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in x:\n",
    "  sent = i\n",
    "  print(sent.capitalize() + '.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPQMJW-emPtf",
    "outputId": "faae1151-b7dc-4b21-aea5-2f50d64e94a3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 70,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "As ipfs 41 to enable interactions with the blockchain the.\n",
      "Can learn from international methods such as the scale of.\n",
      "10 furthermore incentivizing peer reviewing via proper attribution and recognition.\n",
      "Need to be recorded saved and copied the more node.\n",
      "Management and other stakeholders to open their own keys are.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **4-Gram Predictor**"
   ],
   "metadata": {
    "id": "6sHBAnJf5GM9",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "gen_sents = []"
   ],
   "metadata": {
    "id": "_OO0N9-4WnZu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 71,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in range (0,5):\n",
    "  model = NGrams(words=words, sentence=quad_str_lst[randint(0,9850)])\n",
    "  \n",
    "  for j in range(0,6):\n",
    "    values = model.model_selection_3()\n",
    "    vaules_dict = dict(values)\n",
    "    max_value = max(vaules_dict, key=vaules_dict.get)\n",
    "    value = max_value\n",
    "    model.add_tokens(value)\n",
    "\n",
    "  gen_sents.append(model.get_tokens())"
   ],
   "metadata": {
    "id": "RLu2QgNOUVN1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 72,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = [' '.join(i) for i in gen_sents]"
   ],
   "metadata": {
    "id": "iKOlG6Ppjr2e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in x:\n",
    "  sent = i\n",
    "  print(sent.capitalize() + '.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k1NR76Fkjwyr",
    "outputId": "f44ba6a6-70ef-416b-d101-4f493104e1b6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 74,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ultimately to act as a common ground for performing benchmarks.\n",
      "Set of seed terms of a domain topic associating the.\n",
      "The nodes from malicious actions ca certification is used to.\n",
      "We developed an initial prototype application along with integrations with.\n",
      "Open except that the private information involving transaction nodes will.\n"
     ]
    }
   ]
  }
 ]
}